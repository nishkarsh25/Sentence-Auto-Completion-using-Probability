{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxdjBxBF7hnCAz+INWhWn7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishkarsh25/Sentence-Auto-Completion-using-Probability/blob/main/Auto_completion_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGu8VB8va5TQ",
        "outputId": "c6c461a3-50ad-4ae7-e607-621f55d91962"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from urllib import request\n",
        "from nltk.corpus import brown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
        "response = request.urlopen(url)\n",
        "l = response.read().decode('utf8')\n",
        "\n",
        "url1 = \"https://www.gutenberg.org/cache/epub/27827/pg27827.txt\"\n",
        "response1 = request.urlopen(url1)\n",
        "l+= response1.read().decode('utf8')\n",
        "\n",
        "url2 = \"https://www.gutenberg.org/cache/epub/203/pg203.txt\"\n",
        "response2 = request.urlopen(url2)\n",
        "l+= response2.read().decode('utf8')\n",
        "\n",
        "url3 = \"https://www.gutenberg.org/files/55/55-0.txt\"\n",
        "response3 = request.urlopen(url3)\n",
        "l+= response3.read().decode('utf8')\n",
        "\n",
        "url4 = \"https://www.gutenberg.org/files/10007/10007-0.txt\"\n",
        "response4 = request.urlopen(url4)\n",
        "l+= response4.read().decode('utf8')\n",
        "\n",
        "url5 = \"https://www.gutenberg.org/cache/epub/779/pg779.txt\"\n",
        "response5 = request.urlopen(url5)\n",
        "l+= response5.read().decode('utf8')\n",
        "     \n",
        "corpus = l.split()\n",
        "\n",
        "\n",
        "lower_case_corpus = [w.lower() for w in corpus]\n",
        "vocab = set(lower_case_corpus)\n",
        "\n",
        "print('CORPUS EXAMPLE: ' + str(lower_case_corpus[:30]) + '\\n\\n')\n",
        "print('VOCAB EXAMPLE: ' + str(list(vocab)[:10]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJpzlaPTb5w1",
        "outputId": "69fd7bcc-7b55-4fd0-b4f4-098079960db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CORPUS EXAMPLE: ['\\ufeffthe', 'project', 'gutenberg', 'ebook', 'of', 'crime', 'and', 'punishment,', 'by', 'fyodor', 'dostoevsky', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'united', 'states', 'and', 'most', 'other', 'parts', 'of', 'the']\n",
            "\n",
            "\n",
            "VOCAB EXAMPLE: ['moody', 'starting.', \"tortur'd\", 'addressing,', 'what!”', 'legislating!”', 'confidence', 'bar’ls.”', 'proved', 'lace,']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total words in Corpus: ' + str(len(lower_case_corpus)))\n",
        "print('Vocab of the Corpus: ' + str(len(vocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEyWfoyhcBlR",
        "outputId": "8d2e0a5c-37a8-4279-9064-92e3a29b64dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words in Corpus: 549241\n",
            "Vocab of the Corpus: 46819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_counts={}\n",
        "bigram_counts = {}\n",
        "trigram_counts = {}\n",
        "quadgram_counts={}\n",
        "\n",
        "for i in range(len(lower_case_corpus)):\n",
        "      unigram= (lower_case_corpus[i])\n",
        "      if unigram in unigram_counts.keys():\n",
        "         unigram_counts[unigram] += 1\n",
        "      else:\n",
        "         unigram_counts[unigram] = 1\n",
        "for i in range(len(lower_case_corpus) - 1):\n",
        "      bigram = (lower_case_corpus[i], lower_case_corpus[i+1])\n",
        "      if bigram in bigram_counts.keys():\n",
        "         bigram_counts[bigram] += 1\n",
        "      else:\n",
        "         bigram_counts[bigram] = 1\n",
        "for i in range(len(lower_case_corpus) - 2):\n",
        "      trigram = (lower_case_corpus[i], lower_case_corpus[i+1], lower_case_corpus[i+2])\n",
        "      if trigram in trigram_counts.keys():\n",
        "         trigram_counts[trigram] += 1\n",
        "      else:\n",
        "         trigram_counts[trigram] = 1\n",
        "for i in range(len(lower_case_corpus) - 3):     \n",
        "      quadgram = (lower_case_corpus[i], lower_case_corpus[i+1], lower_case_corpus[i+2], lower_case_corpus[i+3])\n",
        "      if quadgram in quadgram_counts.keys():\n",
        "         quadgram_counts[quadgram] += 1\n",
        "      else:\n",
        "         quadgram_counts[quadgram] = 1\n",
        "      \n",
        "     \n",
        "     \n",
        "print(\"Example, count for unigram ('the') is: \" + str(unigram_counts[('the')]))\n",
        "print(\"Example, count for bigram ('the', 'king') is: \" + str(bigram_counts[('the', 'king')]))\n",
        "print(\"Example, count for trigram ('the', 'king' ,'of') is: \" + str(trigram_counts[('the', 'king','of')]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc4zlcALcESY",
        "outputId": "d3340a89-8cf5-4acf-bddb-51ffc415e82e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example, count for unigram ('the') is: 26098\n",
            "Example, count for bigram ('the', 'king') is: 47\n",
            "Example, count for trigram ('the', 'king' ,'of') is: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function takes sentence as input and suggests possible words that comes after the sentence  \n",
        "def suggest_next_word(input_, bigram_counts, trigram_counts, vocab):\n",
        "    # Consider the last bigram of sentence\n",
        "    tokenized_input = word_tokenize(input_.lower())\n",
        "    last_trigram= tokenized_input[-3:]\n",
        "    last_bigram = tokenized_input[-2:]\n",
        "    last_unigram= tokenized_input[-1:]\n",
        "    \n",
        "    # Calculating probability for each word in vocab\n",
        "    vocab_probabilities = {}\n",
        "    for vocab_word in vocab:\n",
        "        test_quadgram = (last_trigram[0], last_trigram[1], last_trigram[2], vocab_word)\n",
        "        test_trigram = (last_trigram[0], last_trigram[1], last_trigram[2])\n",
        "\n",
        "        test_quadgram_count = quadgram_counts.get(test_quadgram, 0)\n",
        "        test_trigram_count = trigram_counts.get(test_trigram, 0)\n",
        "        \n",
        "        if(test_trigram_count!=0):\n",
        "           probability = test_quadgram_count / test_trigram_count\n",
        "           vocab_probabilities[vocab_word] = probability\n",
        "        \n",
        "        else: \n",
        "          \n",
        "            test_trigram = (last_bigram[0], last_bigram[1], vocab_word)\n",
        "            test_bigram = (last_bigram[0], last_bigram[1])\n",
        "\n",
        "            test_trigram_count = trigram_counts.get(test_trigram, 0)\n",
        "            test_bigram_count = bigram_counts.get(test_bigram, 0)\n",
        "           \n",
        "            if(test_bigram_count!=0):\n",
        "                probability = test_trigram_count / test_bigram_count\n",
        "                vocab_probabilities[vocab_word] = probability\n",
        "            else:\n",
        "             \n",
        "                test_bigram = (last_unigram[0], vocab_word)\n",
        "                test_unigram = (last_unigram[0])\n",
        "\n",
        "                test_bigram_count = bigram_counts.get(test_bigram, 0)\n",
        "                test_unigram_count = unigram_counts.get(test_unigram, 0)\n",
        "                \n",
        "                if(test_unigram_count!=0):\n",
        "                  probability = test_bigram_count / test_unigram_count\n",
        "                  vocab_probabilities[vocab_word] = probability\n",
        "                else:\n",
        "                  vocab_probabilities[vocab_word] = 0\n",
        "\n",
        "        \n",
        "          \n",
        "\n",
        "    \n",
        "    # Sorting the vocab probability in descending order to get top probable words\n",
        "    top_suggestions = sorted(vocab_probabilities.items(), key=lambda x: x[1], reverse=True)[:1]\n",
        "    return top_suggestions[0][0]\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "pVrvoKfXcH1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suggest_next_word('I am the king',bigram_counts, trigram_counts,  vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyXVundvcRmh",
        "outputId": "09a47b8b-ccb7-4ad1-b5c1-080682fdde07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('of', 0.3191489361702128)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suggest_next_word('I am the king of', bigram_counts, trigram_counts, vocab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEi6cOMscV6M",
        "outputId": "b77364af-8cc5-4819-d152-7d3bf555d00a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 0.6)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suggest_next_word('I am the king of france ', bigram_counts, trigram_counts, vocab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMj3KHK3cYBi",
        "outputId": "ab24b33f-e539-4934-84d2-bf304e04d987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('and', 0.6666666666666666)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testfile = open(\"test_words.txt\", \"r\")\n",
        "\n",
        "for aline in testfile:\n",
        "  values=aline.split()\n",
        "  s=values[0]+' '+values[1]+' '+values[2]+' '+values[3]\n",
        "  for i in range(3):\n",
        "   out=suggest_next_word(s, bigram_counts, trigram_counts, vocab)\n",
        "   s=s+' '+out;\n",
        "  print(s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRl6KvhYcaJe",
        "outputId": "e3752473-fd68-4bcc-fa43-244a38a08771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Practice makes a massacre in paris,\n",
            "2. Like share and the other is\n",
            "3. The list has been a peculiar\n",
            "4. She trekked towards the door. .\n",
            "5. Honesty is the same at the\n",
            "6. I am short and stout and\n",
            "7. Thinking of Sanskrit and annotated by\n",
            "8. This is a very different matter\n",
            "9. Plants have a great deal of\n",
            "10. No is a great tree, moody\n",
            "11. Happy neurons generated moody and, moody\n",
            "12. No more excuses to your respected\n",
            "13. Coming all the terms of this\n",
            "14. Library with five hundred dollars’ moody\n",
            "15. And then there was the same\n",
            "16. A sketcher in the same way\n",
            "17. A body in many places. .\n",
            "18. That's the reason of this is,\n",
            "19. My birthday is a great tree,\n",
            "20. I like this to a lady\n",
            "21. What a lovely lady or a\n",
            "22. I would rather be quite independent,\n",
            "23. I want to give some of\n",
            "24. Do you like to do everything\n",
            "25. Put the toys of every description,\n",
            "26. Let us go and inform the\n",
            "27. She found a boy who was\n",
            "28. The ball is over.” moody and,\n",
            "29. I have three little children and\n",
            "30. Please pass the night with them;\n",
            "31. The birds flew into the air\n",
            "32. The dog ran to the place\n",
            "33. She sang a man of great\n",
            "34. The girl went to bed quite\n",
            "35. She ate french and english, moody\n",
            "36. Please close the door. . .\n",
            "37. Winter season is a great tree,\n",
            "38. My new laptop moody and, moody\n",
            "39. I like playing with cards, moody\n",
            "40. Do you know that i am\n",
            "41. I want a fortune,” moody and,\n",
            "42. The sun is a great tree,\n",
            "43. Do you like to do everything\n",
            "44. Please wash your own affairs properly\n",
            "45. I study in the same way\n",
            "46. He is my friend. . .\n",
            "47. I am so sad. . .\n",
            "48. Her dog likes to keep my\n",
            "49. My teacher is a great tree,\n",
            "50. The book is dedicated to my\n"
          ]
        }
      ]
    }
  ]
}